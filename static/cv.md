### Education  
- B.S. Shanghai University of Electricity Power, 2016 - 2020  
- M.S. at Cyberspace Security Lab, Zhejiang University, 2020 - 2023.

### Publications
<font size=5>

(Preprint) Masked Diffusion Models are Fast Learners [arxiv](https://arxiv.org/abs/2306.11363)  
<font size=4> **Jiachen Lei**, *Peng Cheng, Zhongjie Ba*, Kui Ren* </font>

</font>
### Competitions  

#### 2022  
*Ego4d Workshop@ECCV 2022* [link](https://ego4d-data.org/workshops/eccv22/)  

* Result: Ranked **2nd** place in both *OSCC* and *PNR-TL* challenges
* For more details about our methodoloty please refer to our [validation report](https://arxiv.org/abs/2211.15286)
* Team Members: [Shuang Ma](https://www.shuangma.me), [Zhongjie Ba](https://scholar.google.com/citations?user=dO2kc6kAAAAJ&hl=zh-CN)
* For more details about the challenge, please visit workshop [website](https://ego4d-data.org/workshops/eccv22/)


*DeepFake Game Competition (DFGC) @ IJCB 2022* 
  
*Creation Track* [link](https://codalab.lisn.upsaclay.fr/competitions/2149)  

* Result: Ranked **3rd** place at stage 1 (score: 18.077/20.727) and stage 2 (score: 23.818/26.959).  
* Takeaways of our methodology:  
    *  Improved SimSwap postprocessing with Splining and Global Contrast Factor (GCF) adjustment.
    *  Reproduced HRFS for high quality face swapping (official code is not available).
    *  Experimented with newly proposed face swapping method MetaPixel
* Team Members: [Zhongjie Ba](https://scholar.google.com/citations?user=dO2kc6kAAAAJ&hl=zh-CN)  
* For more details about the competition, please visit official [Evaluation Result](https://codalab.lisn.upsaclay.fr/competitions/2149#learn_the_details-evaluation)  


*Detection Track* [link](https://codalab.lisn.upsaclay.fr/competitions/2149)  

* Result: Ranked **4th** place. We achieved similar results to other teams with smaller model and less training expense
* Team Members: Jieming Zhong, Weilun Dai, Kaiqiang Fu and [Zhongjie Ba](https://scholar.google.com/citations?user=dO2kc6kAAAAJ&hl=zh-CN)  
* For more details about the competition, please visit official [Evaluation Result](https://codalab.lisn.upsaclay.fr/competitions/3523#results)

---

#### 2021  

*The 3rd Chinese AI Competition* [link](https://ai.xm.gov.cn/competition/competition-detail.html?id=a8e0c40dbb2347fba8b3c9a6294efa5b) - Tracks: [AI based video forgery](https://ai.xm.gov.cn/competition/project-detail.html?id=7533e49def25456a88b3be38f3b967b2&competeId=a8e0c40dbb2347fba8b3c9a6294efa5b) and [Deepfake video detection](https://ai.xm.gov.cn/competition/project-detail.html?id=c0261ec7bff74ab5ab77adefee284081&competeId=a8e0c40dbb2347fba8b3c9a6294efa5b)  
 
  - Result: won ***A*** price (highest price) in track: AI based video forgery (only 2 out of 164 teams were awarded A price)  
  - Team members: Xiaodong Chen, Huiyu Xu, Liu liu and [Zhibo Wang](https://scholar.google.com/citations?user=0ox7zDkAAAAJ&hl=en)  
  <!-- * More details are in Blog ðŸ‘‰[CAIC21]() -->  

---  

### Research Experience

---


<div style="display:flex">
<p> Mitigate the high expenses of tranining diffusion model</p>
<p style="position:absolute; left:60%"> Ongoing </p>
</div>  


<!-- --- -->


<div style="display:flex">
<p>Deepfake Detection</p>
<p style="position:absolute; left:60%"> Onhold </p>
</div>  

* Study the artifacts in generated image brought by deepfake methods

---  

<div style="display:flex">
<p>Self-supervised video learning</p>
<p style="position:absolute; left:60%"> May, 2022 ~ Now  </p>
</div>

  * Learning multi-modality video representation on ego-centric videos via self-supervised learning
  * Work with [ShuangMa](https://www.microsoft.com/en-us/research/people/shuama/), a senior researcher from Micosoft Research
   <!-- * Paper Link: Soon -->

<div style="display:flex">
<p>Fairness of Federated Learning</p>
<p style="position:absolute; left:60%">From Sep to Dec, 2021   </p>
</div>

  * Second author of paper: *Improving Fairness in Heterogeneous Federated Learning* (Not publicly available)
  * Work with Shaoxiang Qing from Cyber-Physical Intelligence Lab, McGill University 

---

<!-- <div style="display:flex">
<p>Place holder</p>
<p style="position:absolute; left:60%"> someday in the future </p>
</div>   -->
  


### Internship

<div style="display:flex">
<p>Microsoft Research</p>
<p style="position:absolute; left:60%"> From May, 2022 ~ Now </p>
</div>  

  * Advised by: [ShuangMa](https://www.microsoft.com/en-us/research/people/shuama/)  
  * Task: self-supervised multi-modality learning on ego-centric videos  
  * Progress: Ongoing  



  <!-- Relative Blogs:  
  [1] : [Modeling camera fingerprint extraction via EM]()  
  [2] : -->

<!-- * Can independently reproducing algorithms introduced in paper. e.g., [HRFS](), [Face2Face]()  
  
  Relative Blogs:  
  [1] : [Reproducing HRFS]()  
  [2] : [Reproducing Face2Face]()   -->

<!-- ### Publications -->
