<html>
<header>
    <title> Jiachen Lei's Home Page</title>

    <style>
        body {
            padding:0;
            margin:0;
            font-size: 20px;
            font-family: Arial, sans-serif;
        }
        .navigate {
            width: 100%;
            height: 3em;
            background-color: hsla(0,0%,94.1%,.9);
            display: flex;
            justify-content: flex-start;
            align-items: center;
            justify-content: space-between;
        }
        .container {
            width: 100%;
            padding-right: 15px;
            padding-left: 15px;
            margin-right: 140px;
            margin-left: 140px;
            display:flex;
            justify-content: flex-start;
            align-items: center;
        }
        .navbar-brand{
            display: inline-block;
            padding-top: .3125rem;
            padding-bottom: .3125rem;
            margin-right: 1rem;
            font-size: 1.25rem;
            line-height: inherit;
            white-space: nowrap;
        }
        .navbar-nav{
            display: flex!important;
        }
        .nav-link{
            display: block;
            color: rgba(0,0,0,.5);
            padding: .5rem 1rem;
            text-decoration: none;
            background-color: transparent;
        }
    </style>

    

    <style>
        #cv-container{
            display: flex;
            width: 100%;
        }

        .cv-lnav{
            position: absolute;
            height:auto;
            left: 0;
            width: 20%;
        }

        .cv-content{
            margin: 0 20% 30px 20%;
            height: auto;
            width: 60%;
        }
        .cv-rnav{
            position: absolute;
            height:auto;
            right: 0;
            width: 20%;
        }

    </style>



</header>

<body>

<div>
    <nav class="navigate">
        <div class="container">
            <p class="navbar-brand" style="color: rgba(0,0,0,.9)">
                Welcome to Jiachen Lei's Home Page
            </p>
            <div class="navbar-nav"">
                <a href="/" class="nav-link">Home</a>
                <a href="/cv" class="nav-link">CV</a>
                <a href="/blog-nav" class="nav-link">Blogs</a>
            </div>
        </div>
    </nav>
    <div class="content">
        

<div id="cv-container"> 
    
    <div class = "cv-lnav">
        <h1></h1>
    </div>
    <div class = "cv-content"><h3>Education</h3>
<ul>
<li>B.S. Shanghai University of Electricity Power, 2020  </li>
<li>M.S. at Cyberspace Security Lab, Zhejiang University, 2023. Advised by <a href="https://scholar.google.com/citations?user=dO2kc6kAAAAJ&amp;hl=zh-CN">Zhongjie Ba</a></li>
</ul><h3>Skills</h3>
<ul>
<li>Generative Modeling (GAN, VAE, DDPM), Deepfake Detection, Representation Learning </li>
<li>Programming: Pytorch/Python/C</li>
</ul><h3>Competitions</h3><h4>2022</h4>
<p><a href="https://ego4d-data.org/workshops/eccv22/">Ego4d Workshop@ECCV 2022</a>  </p><ul>
<li>Result: Ranked <strong>2nd</strong> place in both OSCC and PNR-TL challenges</li>
<li>For more details about our methodoloty please refer to our <a href="https://arxiv.org/abs/2211.15286">validation report</a></li>
<li>Team Members: Me, <a href="https://www.shuangma.me">Shuang Ma</a>, <a href="https://scholar.google.com/citations?user=dO2kc6kAAAAJ&amp;hl=zh-CN">Zhongjie Ba</a></li>
<li>For more details about the challenge, please visit workshop <a href="https://ego4d-data.org/workshops/eccv22/">website</a></li>
</ul><p><a href="https://codalab.lisn.upsaclay.fr/competitions/2149">DeepFake Game Competition (DFGC) @ IJCB 2022 - Creation Track</a>  </p><ul>
<li>Result: Ranked <strong>3rd</strong> place at stage 1 (score: 18.077/20.727) and stage 2 (score: 23.818/26.959).  </li>
<li>Takeaways of our methodology:  <ul>
<li>Improved SimSwap postprocessing with Splining and Global Contrast Factor (GCF) adjustment.</li>
<li>Reproduced HRFS for high quality face swapping (official code is not available).</li>
<li>Experimented with newly proposed face swapping method MetaPixel</li>
</ul>
</li>
<li>Team Members: Me and <a href="https://scholar.google.com/citations?user=dO2kc6kAAAAJ&amp;hl=zh-CN">Zhongjie Ba</a>  </li>
<li>For more details about the competition, please visit official <a href="https://codalab.lisn.upsaclay.fr/competitions/2149#learn_the_details-evaluation">Evaluation Result</a>  </li>
</ul><p><a href="https://codalab.lisn.upsaclay.fr/competitions/2149">DeepFake Game Competition (DFGC) @ IJCB 2022 - Detection Track</a>  </p><ul>
<li>Result: Ranked <strong>4th</strong> place. We achieved similar results to other teams with smaller model and less training expense</li>
<li>Team Members: Me(team leader), Jieming Zhong, Weilun Dai, Kaiqiang Fu and <a href="https://scholar.google.com/citations?user=dO2kc6kAAAAJ&amp;hl=zh-CN">Zhongjie Ba</a>  </li>
<li>For more details about the competition, please visit official <a href="https://codalab.lisn.upsaclay.fr/competitions/3523#results">Evaluation Result</a></li>
</ul><hr /><h4>2021</h4><p><a href="https://ai.xm.gov.cn/competition/competition-detail.html?id=a8e0c40dbb2347fba8b3c9a6294efa5b">The 3rd Chinese AI Competition</a> - Tracks: <a href="https://ai.xm.gov.cn/competition/project-detail.html?id=7533e49def25456a88b3be38f3b967b2&amp;competeId=a8e0c40dbb2347fba8b3c9a6294efa5b">AI based video forgery</a> and <a href="https://ai.xm.gov.cn/competition/project-detail.html?id=c0261ec7bff74ab5ab77adefee284081&amp;competeId=a8e0c40dbb2347fba8b3c9a6294efa5b">Deepfake video detection</a>  </p>
<ul>
<li>Result: won <strong><em>A</em></strong> price (highest price) in track: AI based video forgery (only 2 out of 164 teams were awarded A price)  </li>
<li>Team members: Me(team leader), Xiaodong Chen, Huiyu Xu, Liu liu and <a href="https://scholar.google.com/citations?user=0ox7zDkAAAAJ&amp;hl=en">Zhibo Wang</a><br />
  <!-- * More details are in Blog ðŸ‘‰[CAIC21]() -->
</li>
</ul><hr /><h3>Research Experience</h3><hr /><div style="display:flex">
<p> Mitigate the high expenses of tranining diffusion model</p>
<p style="position:absolute; left:60%"> Ongoing </p>
</div><!-- --- --><div style="display:flex">
<p>Deepfake Detection</p>
<p style="position:absolute; left:60%"> Onhold </p>
</div><ul>
<li>Study the artifacts in generated image brought by deepfake methods</li>
</ul><hr /><div style="display:flex">
<p>Self-supervised video learning</p>
<p style="position:absolute; left:60%"> May, 2022 ~ Now  </p>
</div><ul>
<li>Learning multi-modality video representation on ego-centric videos via self-supervised learning</li>
<li>Work with <a href="https://www.microsoft.com/en-us/research/people/shuama/">ShuangMa</a>, a senior researcher from Micosoft Research
   <!-- * Paper Link: Soon -->
</li>
</ul><div style="display:flex">
<p>Fairness of Federated Learning</p>
<p style="position:absolute; left:60%">From Sep to Dec, 2021   </p>
</div><ul>
<li>Second author of paper: <a href="">Improving Fairness in Heterogeneous Federated Learning</a> (Not publicly available)</li>
<li>Work with Shaoxiang Qing from Cyber-Physical Intelligence Lab, McGill University </li>
</ul><hr /><!-- <div style="display:flex">
<p>Place holder</p>
<p style="position:absolute; left:60%"> someday in the future </p>
</div>   --><h3>Internship</h3><div style="display:flex">
<p>Microsoft Research (Remote)</p>
<p style="position:absolute; left:60%"> From May, 2022 ~ Now </p>
</div><ul>
<li>Advised by: <a href="https://www.microsoft.com/en-us/research/people/shuama/">ShuangMa</a>  </li>
<li>Task: self-supervised multi-modality learning on ego-centric videos  </li>
<li>Progress: Ongoing  </li>
</ul><!-- Relative Blogs:  
  [1] : [Modeling camera fingerprint extraction via EM]()  
  [2] : --><!-- * Can independently reproducing algorithms introduced in paper. e.g., [HRFS](), [Face2Face]()  

  Relative Blogs:  
  [1] : [Reproducing HRFS]()  
  [2] : [Reproducing Face2Face]()   --><!-- ### Publications --></div>
    <div class = "cv-rnav">
        <h1></h1>
    </div>

</div>


    </div>
    <div class="footer">

    </div>

</div>


    
</body>

 

</html>



